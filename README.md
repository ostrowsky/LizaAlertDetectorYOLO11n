# Телеграм-бот и новая модель детекции для ПСО Лиза Алерт

## Исходная задача и цели проекта
Поисково-спасательный отряд «Лиза Алерт» регулярно проводит операции по поиску пропавших людей в лесах и других труднодоступных местах. Для быстрого обзора больших территорий применяются дроны, снимающие местность с высоты ~40–50 м.
С одной поисковой операции получается несколько тысяч фотографий, которые волонтёры сейчас просматривают вручную – это очень долго и утомительно: уже через пару часов глаза устают, а скорость поиска критически важна
Цель данного проекта – разработать систему компьютерного зрения, способную автоматически обнаруживать людей на аэрофотоснимках с дронов, чтобы ускорить работу поисковиков и не пропустить ни одного человека. 
Ключевые требования – высокая полнота обнаружения (Recall) при приемлемой точности, а также возможность работать в полевых условиях на обычных устройствах (например, ноутбуках без мощных GPU)

# Продуктовый трек: интерфейс и внедрение модели
Чтобы сделать технологию удобной для волонтёров, был выбран интерфейс в виде Telegram-бота. Такой подход не требует специального софта: достаточно отправить фотографии боту с любого устройства, и модель вернёт изображения с разметкой найденных людей. 
MVP-прототип – бот @LizaAlertDetectorBot, который принимает как одиночные снимки, так и батчи изображений, обрабатывает их нашей моделью и возвращает результат с выделенными рамкой целями. 
Telegram-бот упрощает тестирование и демонстрацию модели: поисковики могут сразу попробовать инструмент в привычном мессенджере, а разработчики получают раннюю обратную связь. 
Внедрение модели через бот позволяет быстро интегрировать её в рабочий процесс отряда: волонтёры могут оперативно прогонять новые снимки через нейросеть и получать подсказки о возможных обнаружениях.

# Технический трек: данные, модель и обучение

## Датасет и подготовка данных
Для обучения модели был сформирован мастер-датасет, объединяющий несколько поднаборов реальных снимков поисковых операций от проекта Lacmus (инициатива ML для поиска людей). В итоговый набор вошли данные из разных регионов и сезонов:
- spring_korolev_2019.dvc (весна, Королёв 2019)
- summer_moscow_2019.dvc (лето, Московская обл. 2019)
- summer_nnovgorod_2021.dvc (лето, Нижний Новгород 2021)
- summer_tambov_2019.dvc (лето, Тамбов 2019)
- winter_moscow_2018.dvc (зима, Московская обл. 2018)
  
Источник данных - https://github.com/lacmus-foundation/ladd-and-weights

Объединение этих наборов обеспечило разнообразие условий (разные ландшафты, время года, фон и т.д.), что важно для обобщающей способности модели. 
Все исходные изображения были разбиты на перекрывающиеся тайлы размером 1024×1024 пикселя (overlap=256 px) для удобства обучения и последующего инференса.
Тайлирование снимков решает проблему малого масштаба объектов: человек занимает крошечную область большого фото, поэтому модель обучалась на увеличенных фрагментах, где цель крупнее. 
Перекрытие тайлов на 256 пикс. гарантирует, что человек на стыке кадров попадёт целиком хотя бы в один тайл.

## Обучение модели YOLO11n
В качестве ядра детектора выбрана современная архитектура YOLO семейства Ultralytics. После экспериментов с разными версиями было решено использовать облегчённую модель YOLO11n (nano) – она показала высокое качество при небольшом размере.
Модель обучалась на сформированном мастер-датасете; для сравнения также обучалась модель YOLOv5 схожего класса. Результаты на валидации (тайлы 1024×1024) продемонстрировали заметный выигрыш новой модели:
YOLOv5 (модель ~7 млн параметров): mAP@50 = 0.943, mAP@50-95 = 0.578
YOLO11n (модель ~2.5 млн параметров): mAP@50 = 0.976, mAP@50-95 = 0.726
Как видно, YOLO11n превосходит YOLOv5 по точности (особенно на строгой метрике mAP@50-95) при значительно меньшем числе параметров. Количество параметров удалось снизить с ~7 млн до ~2.5 млн – более чем в 2.5 раза – без потери качества. 
Это означает, что финальная модель занимает меньше места и требует меньше ресурсов для работы. 


## Инференс и оптимизация под CPU
Сокращение размеров модели позволило достичь высокой скорости инференса и даже выполнять распознавание на CPU без существенных задержек.
Для волонтёров это критично: поиск часто ведётся в полевых условиях без доступа к облакам и GPU, приходится запускать нейросеть локально на обычном ноутбуке
YOLO11n отлично подходит под эти ограничения – по оценкам, на современном CPU инференс занимает доли секунды на изображение 1024×1024, а на средних GPU достигает обработки в реальном времени. 
Благодаря этому, весь пайплайн обнаружения может работать автономно на местах поисков. Пайплайн инференса по сценам: исходные большие снимки обрабатываются следующим образом: каждое изображение режется на тайлы 1024×1024 (с тем же overlap=256), 
затем модель запускается на каждом тайле, после чего предсказания объединяются назад в координаты оригинального изображения. 
Для объединения результатов применяется масштабирование координат боксов в исходный размер. 
Дополнительно могут применяться фильтры по порогу уверенности модели, чтобы отсеять ложные срабатывания.

## Информация о модели и скорость инференса
Разработанная модель YOLO11n имеет всего ~2.6 млн параметров (для сравнения, даже «младшая» YOLOv5s – ~7 млн). Вес финального чекпойнта модели составляет порядка нескольких мегабайт, что удобно для развёртывания в автономных условиях.
Несмотря на компактность, модель показывает высокую точность, пользуясь улучшенной архитектурой YOLO поколения 11.
Скорость работы: на современном CPU (например, Intel Core i7) модель способна обрабатывать изображения с ощутимой скоростью – по оценке, 1 тайл 1024×1024 обрабатывается примерно за 0.2–0.3 секунды. 
Полный снимок (несколько тайлов) анализируется за считанные секунды, что в разы быстрее ручного просмотра. На GPU инференс идёт ещё быстрее: даже на мобильных видеокартах время на кадр сокращается до десятых или сотых долей секунды. 
Таким образом, поиск человека на тысячах фото, который ранее занимал несколько часов, теперь может быть выполнен за минуты автоматической обработкой. 
Отдельно стоит отметить, что модель оптимизирована для работы без доступа к интернету и облачным сервисам. Это отвечает требованиям «Лиза Алерт»: зачастую поисковая операция проходит вдали от связи, поэтому нейросеть должна запускаться локально. 
YOLO11n в сочетании со специальным ПО ом может быть запущена на ноутбуке координатора поисков прямо в полевых условиях – снимки с дрона загружаются в модель и тут же анализируются на том же устройстве.

## Выбор метрики и приоритеты качества
Для оценки качества детекции мы использовали стандартную метрику mean Average Precision (mAP). Однако учитывая специфику задачи, основной акцент делался на показатель mAP@50.
Метрика mAP@50 рассчитывается при пороговом IoU=50%, и для поиска человека этого достаточно: если модель накрыла человека рамкой наполовину, волонтёр всё равно заметит обнаружение. 
Строгая же метрика mAP@50-95 (усреднение по порогам 50–95%) менее показательна в нашем случае, так как требует очень точного облога (что вторично по сравнению с самим фактом обнаружения). 
Recall (полнота) является для нас критически важным показателем – главная цель проекта не пропустить ни одного человека на снимках. 
Мы готовы пожертвовать некоторой точностью (Precision), позволив больше ложных тревог, лишь бы все реальные люди были найдены. 
Поэтому при калибровке модели порог срабатывания выбирался в сторону увеличения чувствительности. Тем не менее, высокий mAP@50 ~97% у YOLO11n указывает, что модель обеспечивает и отличную точность обнаружения при заданном пороге IoU=0.5.

## Сравнение моделей: YOLOv5 vs YOLO11n
Для наглядности приведём сравнение финальных метрик на валидационном наборе тайлов (1024) для новой моделей и полноразмерных изображений для старой:
Модель	mAP@50 (IoU=0.5)	mAP@50-95 (COCO) Precision Recall
| Модель   | mAP@50 (IoU = 0.5) | mAP@50-95 (COCO) | Precision | Recall |
|----------|-------------------:|-----------------:|----------:|-------:|
| YOLOv5   | 0.943              | 0.578            | 0.919     | 0.882  |  
| YOLO11n  | **0.976**          | **0.726**        | **0.947** | **0.945** | 

*YOLOv5*
<img width="957" height="165" alt="image" src="https://github.com/user-attachments/assets/e1d8690f-6c9a-4f74-b8ea-674036d0d28e" />
*YOLO11n*
<img width="1177" height="157" alt="image" src="https://github.com/user-attachments/assets/58fe81f2-60cc-433d-b383-305378d8bcad" />






Как видно из таблицы, новая модель YOLO11n заметно превосходит YOLOv5 по качеству: при допустимом пороге 50% точность почти на 3% выше, а по сложной составной метрике COCO – выше на ~15% абсолютных. 
Это значительный прирост, означающий меньше пропущенных целей и меньше ложных срабатываний. При этом, повторимся, модель YOLO11n в три раза меньше и быстрее, что упрощает её использование на практике.

#  Итоги проекта и дальнейшие шаги
В рамках проекта New Detection Model for Liza Alert удалось создать эффективную и лёгкую модель обнаружения людей на аэрофотоснимках. 
Проведена большая работа: сбор и подготовка данных, обучение модели нового поколения, её оптимизация под ограниченные ресурсы и интеграция в продуктовый прототип (Telegram-бот для волонтёров).
Модель продемонстрировала высокие результаты на тестовых данных, показав, что может обнаруживать до 97% людей на снимках при приемлемом уровне ложных тревог. 
Главное – теперь поисковики получат инструмент, значительно ускоряющий их работу и позволяющий сосредоточить усилия на тех кадрах, где действительно есть вероятность нахождения человека. 
Проект продолжит развиваться: планируется расширять датасет, улучшать алгоритмы фильтрации результатов, а также добавлять функциональность в бот. 
В конечном счёте, цель – внедрить эту нейросеть непосредственно в практику поисковых операций «Лиза Алерт», сделав поиски более технологичными и эффективными.

#  Источники данных и проект «Лакмус»
Данный проект выполняется в рамках инициативы Lacmus – совместной программы сообщества ODS и «Лиза Алерт» по применению Deep Learning для поиска людей
Датасеты для обучения были собраны волонтёрами «Лиза Алерт» в разных регионах России с 2019 года в рамках проекта «Лакмус»
Подробное описание этой инициативы представлено в статье на Habr: «Проект Lacmus: как компьютерное зрение помогает спасать потерявшихся людей»  https://habr.com/ru/news/812741/
Наше решение продолжает идеи «Лакмуса», но использует более новую модель (YOLOv11) и фокусируется на её практической интеграции (бот для поисковиков).
Все разработки ведутся с открытым исходным кодом и нацелены на свободное распространение среди поисково-спасательных отрядов, что соответствует духу сообщества и миссии проекта

# Ссылки на телеграм бот и демо
https://t.me/LizaAlertDetectorBot
https://youtube.com/shorts/Ef8O3AG235A?si=9i3Dmc7GEPudPeTV


# Примеры детектированных изображений
![photo_2025-07-13_12-42-36](https://github.com/user-attachments/assets/3383c96a-a029-4ada-ba29-5242c91edccd)
![photo_2025-07-13_12-42-28](https://github.com/user-attachments/assets/38a4433b-aa20-42f4-813f-47b4dce2ef56)
![photo_2025-07-13_12-42-15](https://github.com/user-attachments/assets/df4f51d4-e7f5-4f88-bc30-b3dadafd06eb)
![photo_2025-07-11_22-00-12](https://github.com/user-attachments/assets/ee45f93e-1e8d-46ef-9393-82535e7b0e46)
![photo_2025-07-11_21-58-56](https://github.com/user-attachments/assets/24afc8b6-ba47-4c27-8c01-5793ca1f38c8)
![photo_2025-07-11_21-58-36](https://github.com/user-attachments/assets/b8a5f6cb-63ce-484a-8acf-d8f2e7db84c0)
![photo_2025-07-10_19-50-06](https://github.com/user-attachments/assets/28d7f1fd-9b44-496f-8740-a04dc4550596)











